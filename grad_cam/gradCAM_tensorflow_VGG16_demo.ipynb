{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradCAM Visualization Demo with VGG16\n",
    "\n",
    "Requirement:\n",
    "\n",
    "* GPU Memory: 6GB or higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install scikit-image\n",
    "# Replace vanila relu to guided relu to get guided backpropagation.\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.ops import gen_nn_ops\n",
    "\n",
    "@ops.RegisterGradient(\"GuidedRelu\")\n",
    "def _GuidedReluGrad(op, grad):\n",
    "    return tf.where(0. < grad, gen_nn_ops.relu_grad(grad, op.outputs[0]), tf.zeros(grad.get_shape()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lb2onehot(labels, num_class=5):\n",
    "    result = tf.zeros([len(labels), num_class])\n",
    "    for idx, lb in enumerate(labels):\n",
    "        result[idx, lb] = 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import utils\n",
    "import pickle\n",
    "\n",
    "# Create mini-batch for demo\n",
    "# Get normalized input. VGG network handles the normalized image internally. \n",
    "test_image = pickle.load(open('test_img.txt', 'rb'))\n",
    "test, _test_lb = [], []\n",
    "for lb in range(5):\n",
    "    test.extend(test_image[lb])\n",
    "    num_lb = len(test_image[lb])\n",
    "    _test_lb.extend([lb]*num_lb)\n",
    "\n",
    "test = np.array(test)\n",
    "test_lb = np.array(_test_lb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from networks import VGG16\n",
    "batch_size = 50\n",
    "eval_graph = tf.Graph()\n",
    "with eval_graph.as_default():\n",
    "    with eval_graph.gradient_override_map({'Relu': 'GuidedRelu'}):\n",
    "    \n",
    "        images = tf.placeholder(tf.float32, [batch_size, 128, 128, 3])\n",
    "        labels = tf.placeholder(tf.int32, [batch_size, ])        \n",
    "        print(images, labels)\n",
    "        is_training = tf.placeholder(tf.bool, name='is_training')\n",
    "        lr = tf.placeholder(tf.float32, [], name='learning_rate')\n",
    "\n",
    "        vgg = VGG16()\n",
    "        vgg.create_network(images, labels, is_training)\n",
    "        \n",
    "        cost = vgg.loss\n",
    "        print('cost:', cost)\n",
    "        \n",
    "        # gradient for partial linearization. We only care about target visualization class. \n",
    "        y_c = tf.reduce_sum(tf.multiply(vgg.output_logit, tf.one_hot(labels,5)), axis=1)\n",
    "        print('y_c:', y_c)\n",
    "        # Get last convolutional layer gradient for generating gradCAM visualization\n",
    "        target_conv_layer = vgg.layer_feat\n",
    "        #target_conv_layer2 = vgg.layer_feat_\n",
    "        #target_conv_lyaer3 = vgg.layer_feat__\n",
    "\n",
    "        target_conv_layer_grad = tf.gradients(y_c, target_conv_layer)[0]\n",
    "        #target_conv_layer_grad2 = tf.gradients(y_c, target_conv_layer2)[0]\n",
    "        #target_conv_layer_grad3 = tf.gradients(y_c, target_conv_layer3)[0]\n",
    "        # Guided backpropagtion back to input layer\n",
    "        gb_grad = tf.gradients(cost, images)[0]\n",
    "        \n",
    "# Run tensorflow \n",
    "\n",
    "with tf.Session(graph=eval_graph) as sess:    \n",
    "    vgg.read_original_weights(sess)\n",
    "    mis_class = []\n",
    "    lb_pair = []\n",
    "    pb_list = []\n",
    "    for iter in range(50):\n",
    "        prob = sess.run(vgg.output, feed_dict={images: test[iter*batch_size:(iter+1)*batch_size]})\n",
    "        \n",
    "        gb_grad_value, target_conv_layer_value, target_conv_layer_grad_value = sess.run([gb_grad, target_conv_layer,target_conv_layer_grad], \n",
    "            feed_dict={images: test[iter*batch_size:(iter+1)*batch_size], \n",
    "                labels: test_lb[iter*batch_size:(iter+1)*batch_size]})\n",
    "    \n",
    "        for i in range(batch_size):\n",
    "            if test_lb[iter*batch_size + i] == np.argmax(prob[i]):\n",
    "                mis_class.append(0)\n",
    "                is_mis = False\n",
    "            else:\n",
    "                mis_class.append(1)\n",
    "                is_mis = True\n",
    "            \n",
    "            lb_pair.append((test_lb[iter*batch_size+i], np.argmax(prob[i])))\n",
    "            pb_list.append(prob[i])\n",
    "\n",
    "            if is_mis:\n",
    "                print(iter*batch_size+i, 'th image was misclassified\\n Label:\\t', \n",
    "                    test_lb[iter*batch_size+i], 'Pred:\\t', np.argmax(prob[i], 'prob_list:\\t', prob[i]))\n",
    "            \n",
    "            #utils.print_prob(prob[i], './synset.txt')\n",
    "            # VGG16 use BGR internally, so we manually change BGR to RGB\n",
    "                      \n",
    "            '''\n",
    "            gradBGR = gb_grad_value[i]\n",
    "            gradRGB = np.dstack((\n",
    "                gradBGR[:, :, 2],\n",
    "                gradBGR[:, :, 1],\n",
    "                gradBGR[:, :, 0],\n",
    "            ))\n",
    "            '''\n",
    "            print(\"GT Label:\\t\", test_lb[iter*batch_size +i])\n",
    "            print(\"Model Output: \\t\", np.argmax(prob[i]))\n",
    "            utils.visualize(test[iter*batch_size+i], target_conv_layer_value[i], target_conv_layer_grad_value[i], gb_grad_value[i])#gradRGB)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
